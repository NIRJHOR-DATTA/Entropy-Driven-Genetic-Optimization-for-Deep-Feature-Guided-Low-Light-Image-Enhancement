{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2211a57-f384-4152-a499-745d39b0feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FA007\\.conda\\envs\\new2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\FA007\\.conda\\envs\\new2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from deap import base, creator, tools\n",
    "import random\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Setup Pretrained Feature Extractor with PyTorch (GPU)\n",
    "# ------------------------------\n",
    "class VGG16FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16FeatureExtractor, self).__init__()\n",
    "        vgg16 = models.vgg16(pretrained=True)\n",
    "        self.features = vgg16.features\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_extractor = VGG16FeatureExtractor().to(device)\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Transformation for feature extractor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_features_torch(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract deep features from an RGB image (numpy array [0,1])\"\"\"\n",
    "    input_tensor = transform((img * 255).astype(np.uint8))\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feats = feature_extractor(input_tensor)\n",
    "    return feats.cpu().numpy().flatten()\n",
    "\n",
    "# ------------------------------\n",
    "# 2. GPU-based Image Enhancement Operators\n",
    "# ------------------------------\n",
    "def enhance_image_gpu(image: np.ndarray, individual: list) -> np.ndarray:\n",
    "    brightness, contrast, gamma = individual\n",
    "    img_tensor = torch.tensor(image, dtype=torch.float32, device=device)\n",
    "    img_bright = torch.clamp(img_tensor + (brightness / 255.0), 0.0, 1.0)\n",
    "    img_contrast = torch.clamp(contrast * img_bright, 0.0, 1.0)\n",
    "    img_gamma = torch.clamp(torch.pow(img_contrast, 1.0 / gamma), 0.0, 1.0)\n",
    "    return img_gamma.cpu().numpy()\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Corrected Fitness Evaluation\n",
    "# ------------------------------\n",
    "def evaluate_individual(individual, original_img, orig_features):\n",
    "    enhanced = enhance_image_gpu(original_img, individual)\n",
    "    img_tensor = torch.tensor(enhanced, dtype=torch.float32, device=device)\n",
    "    gray = 0.114 * img_tensor[:,:,0] + 0.587 * img_tensor[:,:,1] + 0.299 * img_tensor[:,:,2]\n",
    "    hist = torch.histc(gray, bins=256, min=0.0, max=1.0)\n",
    "    prob = hist / torch.sum(hist)\n",
    "    entropy = -torch.sum(prob * torch.log2(prob + 1e-6)).item()\n",
    "\n",
    "    # Deep features\n",
    "    enhanced_rgb = cv2.cvtColor((enhanced * 255).astype(np.uint8), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    feat_enh = extract_features_torch(enhanced_rgb)\n",
    "    feat_dist = np.linalg.norm(orig_features - feat_enh)\n",
    "\n",
    "    # Brightness penalty\n",
    "    mean_b = torch.mean(img_tensor).item()\n",
    "    penalty = 0.0\n",
    "    low, up, factor = 0.35, 0.7, 30.0\n",
    "    if mean_b < low:\n",
    "        penalty += (low - mean_b) * factor\n",
    "    elif mean_b > up:\n",
    "        penalty += (mean_b - up) * factor\n",
    "\n",
    "    return entropy, feat_dist + penalty\n",
    "\n",
    "# ------------------------------\n",
    "# 4. GA Configuration\n",
    "# ------------------------------\n",
    "PARAM_BOUNDS = [(-10, 60), (1.0, 2.0), (1.0, 2.0)]\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "for i, (low, up) in enumerate(PARAM_BOUNDS):\n",
    "    toolbox.register(f\"attr_{i}\", random.uniform, low, up)\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_0, toolbox.attr_1, toolbox.attr_2), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate_individual)\n",
    "\n",
    "def bounded_cx(ind1, ind2):\n",
    "    tools.cxBlend(ind1, ind2, alpha=0.5)\n",
    "    for i, (low, up) in enumerate(PARAM_BOUNDS):\n",
    "        ind1[i] = np.clip(ind1[i], low, up)\n",
    "        ind2[i] = np.clip(ind2[i], low, up)\n",
    "    return ind1, ind2\n",
    "\n",
    "def bounded_mut(ind, indpb):\n",
    "    for i, (low, up) in enumerate(PARAM_BOUNDS):\n",
    "        if random.random() < indpb:\n",
    "            ind[i] += random.gauss(0, (up - low) * 0.1)\n",
    "            ind[i] = np.clip(ind[i], low, up)\n",
    "    return ind,\n",
    "\n",
    "toolbox.register(\"mate\", bounded_cx)\n",
    "toolbox.register(\"mutate\", bounded_mut, indpb=0.4)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Local Search\n",
    "# ------------------------------\n",
    "def local_search(ind, original_img, orig_features, max_iter=8):\n",
    "    best = ind[:]\n",
    "    best_fit = evaluate_individual(best, original_img, orig_features)\n",
    "    for _ in range(max_iter):\n",
    "        neigh = [np.clip(p + random.uniform(-0.5, 0.5), lo, hi)\n",
    "                 for p, (lo, hi) in zip(best, PARAM_BOUNDS)]\n",
    "        fit_n = evaluate_individual(neigh, original_img, orig_features)\n",
    "        if (fit_n[0] > best_fit[0]) or (fit_n[0] == best_fit[0] and fit_n[1] < best_fit[1]):\n",
    "            best, best_fit = neigh, fit_n\n",
    "    return best\n",
    "\n",
    "# ------------------------------\n",
    "# 6. GA Routine Without Display\n",
    "# ------------------------------\n",
    "def run_ga(original_img, ngen=35, pop_size=50):\n",
    "    orig_f = original_img.astype(np.float32) / 255.0\n",
    "    orig_rgb = cv2.cvtColor((orig_f * 255).astype(np.uint8), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    feats = extract_features_torch(orig_rgb)\n",
    "\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    for ind in pop:\n",
    "        ind.fitness.values = toolbox.evaluate(ind, orig_f, feats)\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "    for gen in range(ngen):\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        offspring = [toolbox.clone(i) for i in offspring]\n",
    "        # Crossover & Mutation\n",
    "        for i1, i2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.85:\n",
    "                toolbox.mate(i1, i2)\n",
    "                del i1.fitness.values, i2.fitness.values\n",
    "        mut_rate = 0.3 if gen < ngen//2 else 0.2\n",
    "        for m in offspring:\n",
    "            if random.random() < mut_rate:\n",
    "                toolbox.mutate(m)\n",
    "                del m.fitness.values\n",
    "\n",
    "        invalid = [i for i in offspring if not i.fitness.valid]\n",
    "        for i in invalid:\n",
    "            i.fitness.values = toolbox.evaluate(i, orig_f, feats)\n",
    "        pop = toolbox.select(pop + offspring, pop_size)\n",
    "\n",
    "        # Local search on top 20%\n",
    "        top = tools.selBest(pop, max(1, int(0.2 * pop_size)))\n",
    "        for ind in top:\n",
    "            new_p = local_search(ind, orig_f, feats)\n",
    "            new_fit = evaluate_individual(new_p, orig_f, feats)\n",
    "            if (new_fit[0] > ind.fitness.values[0]) or \\\n",
    "               (new_fit[0] == ind.fitness.values[0] and new_fit[1] < ind.fitness.values[1]):\n",
    "                ind[:] = new_p\n",
    "                ind.fitness.values = new_fit\n",
    "\n",
    "    best = tools.selBest(pop, 1)[0]\n",
    "    enhanced = enhance_image_gpu(orig_f, best)\n",
    "    return enhanced\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Batch Processing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d125bfd-7b83-4eed-8835-454e3eaf75d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancing: D:\\new_unpaired\\MEF\\Balloons.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Balloons.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\BelgiumHouse.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\BelgiumHouse.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Cadik.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Cadik.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Candle.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Candle.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Cave.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Cave.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\ChineseGarden.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\ChineseGarden.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Farmhouse.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Farmhouse.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\House.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\House.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Kluki.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Kluki.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Lamp.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Lamp.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Landscape.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Landscape.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\LightHouse.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\LightHouse.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Madison.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Madison.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Memorial.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Memorial.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Office.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Office.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Tower.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Tower.png\n",
      "Enhancing: D:\\new_unpaired\\MEF\\Venice.png\n",
      "Saved enhanced image: D:\\new_unpaired\\MEF_NOLOCALSEARCH\\.\\Venice.png\n"
     ]
    }
   ],
   "source": [
    "# Ablation study variants: three versions of run_ga\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from deap import tools\n",
    "\n",
    "# Assuming all other functions and setup (feature_extractor, extract_features_torch,\n",
    "# enhance_image_gpu, evaluate_individual, local_search, toolbox) are defined as before.\n",
    "\n",
    "def run_ga_no_local_search(original_img, ngen=35, pop_size=50):\n",
    "    \"\"\"GA without the memetic local search step.\"\"\"\n",
    "    orig_f = original_img.astype(np.float32) / 255.0\n",
    "    feats = extract_features_torch(cv2.cvtColor((orig_f*255).astype(np.uint8),\n",
    "                                               cv2.COLOR_BGR2RGB).astype(np.float32)/255.0)\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    for ind in pop:\n",
    "        ind.fitness.values = toolbox.evaluate(ind, orig_f, feats)\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "    \n",
    "    for gen in range(ngen):\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        offspring = [toolbox.clone(i) for i in offspring]\n",
    "        \n",
    "        # Crossover & Mutation (adaptive mutation still applied)\n",
    "        for i1, i2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.85:\n",
    "                toolbox.mate(i1, i2)\n",
    "                del i1.fitness.values, i2.fitness.values\n",
    "        \n",
    "        # adaptive mutation rate\n",
    "        mut_rate = 0.3 if gen < ngen//2 else 0.2\n",
    "        for m in offspring:\n",
    "            if random.random() < mut_rate:\n",
    "                toolbox.mutate(m)\n",
    "                del m.fitness.values\n",
    "        \n",
    "        invalid = [i for i in offspring if not i.fitness.valid]\n",
    "        for i in invalid:\n",
    "            i.fitness.values = toolbox.evaluate(i, orig_f, feats)\n",
    "        pop = toolbox.select(pop + offspring, pop_size)\n",
    "    \n",
    "    best = tools.selBest(pop, 1)[0]\n",
    "    return enhance_image_gpu(orig_f, best)\n",
    "\n",
    "def run_ga_no_adaptive_mutation(original_img, ngen=35, pop_size=50, fixed_mut_rate=0.3):\n",
    "    \"\"\"GA with fixed mutation rate (no adaptive mutation).\"\"\"\n",
    "    orig_f = original_img.astype(np.float32) / 255.0\n",
    "    feats = extract_features_torch(cv2.cvtColor((orig_f*255).astype(np.uint8),\n",
    "                                               cv2.COLOR_BGR2RGB).astype(np.float32)/255.0)\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    for ind in pop:\n",
    "        ind.fitness.values = toolbox.evaluate(ind, orig_f, feats)\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "    \n",
    "    for gen in range(ngen):\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        offspring = [toolbox.clone(i) for i in offspring]\n",
    "        \n",
    "        # Crossover\n",
    "        for i1, i2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.85:\n",
    "                toolbox.mate(i1, i2)\n",
    "                del i1.fitness.values, i2.fitness.values\n",
    "        \n",
    "        # fixed mutation rate across all generations\n",
    "        for m in offspring:\n",
    "            if random.random() < fixed_mut_rate:\n",
    "                toolbox.mutate(m)\n",
    "                del m.fitness.values\n",
    "        \n",
    "        invalid = [i for i in offspring if not i.fitness.valid]\n",
    "        for i in invalid:\n",
    "            i.fitness.values = toolbox.evaluate(i, orig_f, feats)\n",
    "        pop = toolbox.select(pop + offspring, pop_size)\n",
    "    \n",
    "    best = tools.selBest(pop, 1)[0]\n",
    "    return enhance_image_gpu(orig_f, best)\n",
    "\n",
    "def run_nsgaii_only(original_img, ngen=35, pop_size=50):\n",
    "    \"\"\"Pure NSGA-II without local search or any mutation (only crossover).\"\"\"\n",
    "    orig_f = original_img.astype(np.float32) / 255.0\n",
    "    feats = extract_features_torch(cv2.cvtColor((orig_f*255).astype(np.uint8),\n",
    "                                               cv2.COLOR_BGR2RGB).astype(np.float32)/255.0)\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    for ind in pop:\n",
    "        ind.fitness.values = toolbox.evaluate(ind, orig_f, feats)\n",
    "    pop = tools.selNSGA2(pop, len(pop))  # initial sort\n",
    "    \n",
    "    for gen in range(ngen):\n",
    "        # offspring by NSGA-II selection and crossover only\n",
    "        offspring = tools.selNSGA2(pop, pop_size)\n",
    "        offspring = [toolbox.clone(i) for i in offspring]\n",
    "        for i1, i2 in zip(offspring[::2], offspring[1::2]):\n",
    "            toolbox.mate(i1, i2)\n",
    "            del i1.fitness.values, i2.fitness.values\n",
    "        \n",
    "        invalid = [i for i in offspring if not i.fitness.valid]\n",
    "        for i in invalid:\n",
    "            i.fitness.values = toolbox.evaluate(i, orig_f, feats)\n",
    "        pop = tools.selNSGA2(pop + offspring, pop_size)\n",
    "    \n",
    "    front = tools.sortNondominated(pop, k=pop_size, first_front_only=True)[0]\n",
    "    best = sorted(front, key=lambda ind: (-ind.fitness.values[0], ind.fitness.values[1]))[0]\n",
    "    return enhance_image_gpu(orig_f, best)\n",
    "\n",
    "# Example usage:\n",
    "# enhanced_full = run_ga(img)\n",
    "# enhanced_no_ls = run_ga_no_local_search(img)\n",
    "# enhanced_no_am = run_ga_no_adaptive_mutation(img)\n",
    "# enhanced_nsgaii = run_nsgaii_only(img)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_root = r\"D:\\new_unpaired\\MEF\"\n",
    "    output_root = r\"D:\\new_unpaired\\MEF_NOLOCALSEARCH\"\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    for subdir, _, files in os.walk(input_root):\n",
    "        rel_path = os.path.relpath(subdir, input_root)\n",
    "        output_subdir = os.path.join(output_root, rel_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "                continue\n",
    "            in_path = os.path.join(subdir, fname)\n",
    "            img = cv2.imread(in_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: unable to read {in_path}\")\n",
    "                continue\n",
    "            print(f\"Enhancing: {in_path}\")\n",
    "            enhanced = run_ga_no_local_search(img, ngen=5, pop_size=60)\n",
    "            out_img = (enhanced * 255).astype(np.uint8)\n",
    "            out_path = os.path.join(output_subdir, fname)\n",
    "            cv2.imwrite(out_path, out_img)\n",
    "            print(f\"Saved enhanced image: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a29d1f-36c6-4dd7-acf8-391677081582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
